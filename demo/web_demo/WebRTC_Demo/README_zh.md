# WebRTC å®æ—¶è§†é¢‘äº¤äº’æ¼”ç¤º

åŸºäº WebRTC å®ç°çš„å…¨åŒå·¥å®æ—¶è§†é¢‘äº¤äº’æ–¹æ¡ˆï¼Œæ”¯æŒæµå¼è¾“å…¥è¾“å‡ºï¼Œå…·æœ‰é«˜å“åº”ã€ä½å»¶è¿Ÿçš„ç‰¹æ€§ã€‚

ğŸ“– [English Version](./README.md)

## æ¦‚è¿°

æœ¬æ¼”ç¤ºé‡‡ç”¨ WebRTC æŠ€æœ¯å®ç°äº†**å…¨åŒå·¥å®æ—¶è§†é¢‘äº¤äº’**æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆå¡«è¡¥äº†ç›®å‰å¼€æºç¤¾åŒºä¸­**æµå¼åŒå·¥å¯¹è¯æ–¹æ¡ˆ**çš„æŠ€æœ¯ç©ºç™½ï¼Œä¸ºå®æ—¶å¤šæ¨¡æ€äº¤äº’æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚

> [!WARNING]
> **å…³äºéŸ³è´¨çš„è¯´æ˜**ï¼šç›®å‰æœ¬åœ°éƒ¨ç½²ç‰ˆæœ¬çš„ token2wav æ¨¡å—å­˜åœ¨å·²çŸ¥é—®é¢˜ï¼Œå¯èƒ½ä¼šå¯¼è‡´è½»å¾®çš„â€œç”µæµéŸ³â€æ•ˆæœï¼ŒéŸ³è´¨è¡¨ç°å¯èƒ½ç•¥é€Šäºåœ¨çº¿ Demoã€‚æˆ‘ä»¬æ­£åœ¨åŠ æ€¥å¤„ç†ï¼Œé¢„è®¡å°†åœ¨è¿‘æœŸï¼ˆå‡ å¤©å†…ï¼‰ä¿®å¤ã€‚

## å‰ç½®æ¡ä»¶

### 1. å®‰è£… Docker Desktop (macOS)

```bash
# ä½¿ç”¨ Homebrew å®‰è£…
brew install --cask docker

# æˆ–ä»å®˜ç½‘ä¸‹è½½ï¼šhttps://www.docker.com/products/docker-desktop

# éªŒè¯å®‰è£…
docker --version
```

### 2. ç¼–è¯‘ llamacpp-omni æ¨ç†æœåŠ¡

```bash
# å…‹éš†å¹¶è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/llama.cpp-omni

# ç¼–è¯‘ï¼ˆmacOS é»˜è®¤å¯ç”¨ Metal åŠ é€Ÿï¼‰
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build --target llama-server -j

# éªŒè¯ç¼–è¯‘ç»“æœ
ls -la build/bin/llama-server
```

### 3. å‡†å¤‡ GGUF æ¨¡å‹æ–‡ä»¶

ä¸‹è½½å¹¶æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡æ¨¡å‹æ–‡ä»¶ï¼š

```
<MODEL_DIR>/
â”œâ”€â”€ MiniCPM-o-4_5-Q4_K_M.gguf        # LLM ä¸»æ¨¡å‹ (~5GB)
â”œâ”€â”€ audio/                            # éŸ³é¢‘ç¼–ç å™¨
â”‚   â””â”€â”€ MiniCPM-o-4_5-audio-F16.gguf
â”œâ”€â”€ vision/                           # è§†è§‰ç¼–ç å™¨
â”‚   â””â”€â”€ MiniCPM-o-4_5-vision-F16.gguf
â”œâ”€â”€ tts/                              # TTS æ¨¡å‹
â”‚   â”œâ”€â”€ MiniCPM-o-4_5-tts-F16.gguf
â”‚   â””â”€â”€ MiniCPM-o-4_5-projector-F16.gguf
â””â”€â”€ token2wav-gguf/                   # Token2Wav æ¨¡å‹
    â”œâ”€â”€ encoder.gguf
    â”œâ”€â”€ flow_matching.gguf
    â”œâ”€â”€ flow_extra.gguf
    â”œâ”€â”€ hifigan2.gguf
    â””â”€â”€ prompt_cache.gguf
```

## å¿«é€Ÿå¼€å§‹

æˆ‘ä»¬æä¾›äº†é¢„æ„å»ºçš„ Docker é•œåƒï¼Œæ–¹ä¾¿å¿«é€Ÿéƒ¨ç½²å’Œä½“éªŒã€‚Docker é•œåƒåŒ…å«äº†æ‰€æœ‰å¿…è¦çš„ä¾èµ–å’Œé…ç½®ã€‚

### macOS (Apple Silicon)

**è®¾å¤‡è¦æ±‚**ï¼šApple Silicon Macï¼ˆM1/M2/M3/M4ï¼‰ï¼Œ**æ¨èä½¿ç”¨ M4** ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

ä¸‹è½½é€‚ç”¨äº macOS çš„ Docker é•œåƒï¼š

ğŸ“¦ [ä¸‹è½½ Docker é•œåƒ (macOS)](https://drive.google.com/file/d/1i7HrGBZE3E-6lsrHjQgaEQK0Qxdi6tSN/view?usp=sharing)

### éƒ¨ç½²æ­¥éª¤

#### ç¬¬ä¸€æ­¥ï¼šè§£å‹å¹¶åŠ è½½ Docker é•œåƒ

```bash
# è§£å‹å‹ç¼©åŒ…
unzip omni_docker.zip
cd omni_docker

# åŠ è½½ Docker é•œåƒ
docker load -i o45-frontend.tar
docker load -i omini_backend_code/omni_backend.tar
```

#### ç¬¬äºŒæ­¥ï¼šå®‰è£… Python ä¾èµ–

```bash
# å®‰è£…æ¨ç†æœåŠ¡æ‰€éœ€çš„ Python ä¾èµ–
pip install -r cpp_server/requirements.txt
```

#### ç¬¬ä¸‰æ­¥ï¼šä¸€é”®éƒ¨ç½²ï¼ˆæ¨èï¼‰

> **æ³¨æ„**ï¼š`deploy_all.sh` è„šæœ¬ä½äº `omni_docker` ç›®å½•ä¸‹ã€‚

```bash
# è¿è¡Œéƒ¨ç½²è„šæœ¬ï¼ŒæŒ‡å®šå¿…è¦è·¯å¾„
./deploy_all.sh \
    --cpp-dir /path/to/llama.cpp-omni \
    --model-dir /path/to/gguf

# ä½¿ç”¨åŒå·¥æ¨¡å¼
./deploy_all.sh \
    --cpp-dir /path/to/llama.cpp-omni \
    --model-dir /path/to/gguf \
    --duplex
```

è„šæœ¬è‡ªåŠ¨å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
- æ£€æŸ¥ Docker ç¯å¢ƒ
- è‡ªåŠ¨æ›´æ–° LiveKit é…ç½®ä¸­çš„æœ¬æœº IP
- å¯åŠ¨ Docker æœåŠ¡ï¼ˆå‰ç«¯ã€åç«¯ã€LiveKitã€Redisï¼‰
- å®‰è£… Python ä¾èµ–
- å¯åŠ¨ C++ æ¨ç†æœåŠ¡
- æ³¨å†Œæ¨ç†æœåŠ¡åˆ°åç«¯

#### ç¬¬å››æ­¥ï¼šè®¿é—® Web ç•Œé¢

```bash
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€å‰ç«¯
open http://localhost:3000
```

### æœåŠ¡ç«¯å£è¯´æ˜

| æœåŠ¡ | ç«¯å£ | è¯´æ˜ |
|------|------|------|
| å‰ç«¯ | 3000 | Web UI |
| åç«¯ | 8021 | åç«¯ API |
| LiveKit | 7880 | å®æ—¶é€šä¿¡ |
| æ¨ç†æœåŠ¡ | 9060 | Python HTTP API |

> æ›´å¤šå¹³å°æ”¯æŒï¼ˆLinuxã€Windowsï¼‰å³å°†æ¨å‡ºã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ”„ å…¨åŒå·¥é€šä¿¡
- æ”¯æŒéŸ³è§†é¢‘åŒå‘åŒæ—¶ä¼ è¾“
- è‡ªç„¶æµç•…çš„å¯¹è¯ä½“éªŒï¼Œæ— éœ€ç­‰å¾…è½®æ¬¡åˆ‡æ¢

### âš¡ é«˜å“åº”ä½å»¶è¿Ÿ
- æµå¼è¾“å…¥è¾“å‡ºï¼Œå®ç°å®æ—¶äº¤äº’
- ç«¯åˆ°ç«¯å»¶è¿Ÿä¼˜åŒ–
- å¯¹è¯è¿‡ç¨‹ä¸­å³æ—¶åé¦ˆ

### ğŸš€ åŸç”Ÿæ”¯æŒ llamacpp-omni
- æ— ç¼é›†æˆ [llamacpp-omni](https://github.com/OpenBMB/llama.cpp/tree/minicpm-omni) ä½œä¸ºæ¨ç†åç«¯
- å¿«é€Ÿéƒ¨ç½²ï¼Œç®€å•é…ç½®
- é«˜æ•ˆçš„èµ„æºåˆ©ç”¨

### ğŸ¯ å¿«é€Ÿä½“éªŒ MiniCPM-o 4.5
- å¿«é€Ÿä½“éªŒ MiniCPM-o 4.5 çš„å®Œæ•´èƒ½åŠ›
- å®æ—¶å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆ
- è¯­éŸ³ä¸è§†é¢‘äº¤äº’ä¸€ä½“åŒ–

## æŠ€æœ¯äº®ç‚¹

- **WebRTC åè®®**ï¼šä¸šç•Œæ ‡å‡†çš„å®æ—¶é€šä¿¡åè®®
- **æµå¼æ¶æ„**ï¼šè¿ç»­æ•°æ®æµï¼Œäº¤äº’æµç•…
- **åŒå·¥è®¾è®¡**ï¼šå¡«è¡¥å¼€æºç¤¾åŒºæµå¼åŒå·¥å¯¹è¯æ–¹æ¡ˆçš„ç©ºç™½

## å³å°†å¼€æº

> ğŸš§ **æˆ‘ä»¬æ­£åœ¨æ•´ç†å’Œå®Œå–„ä»£ç ï¼Œå®Œæ•´æºä»£ç å°†åœ¨æœªæ¥å‡ å¤©å†…å¼€æºï¼Œæ•¬è¯·æœŸå¾…ï¼**

## ç›¸å…³èµ„æº

- [MiniCPM-o 4.5 æ¨¡å‹](https://huggingface.co/openbmb/MiniCPM-o-4_5)
- [llamacpp-omni æ¨ç†åç«¯](https://github.com/OpenBMB/llama.cpp/tree/minicpm-omni)
